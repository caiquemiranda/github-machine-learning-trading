{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# dados fin\n",
    "import yfinance as yf\n",
    "\n",
    "start = '2021-01-01'\n",
    "end = '2023-06-06'\n",
    "\n",
    "data = yf.download('AAPL', \n",
    "                   start=start,\n",
    "                   end=end)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.to_csv('data_/AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>127.503662</td>\n",
       "      <td>143301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>129.080078</td>\n",
       "      <td>97664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>124.735031</td>\n",
       "      <td>155088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>128.991425</td>\n",
       "      <td>109578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>130.104767</td>\n",
       "      <td>105158200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2021-01-04  133.520004  133.610001  126.760002  129.410004  127.503662   \n",
       "1  2021-01-05  128.889999  131.740005  128.429993  131.009995  129.080078   \n",
       "2  2021-01-06  127.720001  131.050003  126.379997  126.599998  124.735031   \n",
       "3  2021-01-07  128.360001  131.630005  127.860001  130.919998  128.991425   \n",
       "4  2021-01-08  132.429993  132.630005  130.229996  132.050003  130.104767   \n",
       "\n",
       "      Volume  \n",
       "0  143301900  \n",
       "1   97664900  \n",
       "2  155088000  \n",
       "3  109578200  \n",
       "4  105158200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_average(data, window):\n",
    "    return data['Close'].rolling(window=window).mean()\n",
    "\n",
    "# Vamos testar para diferentes períodos de média móvel (por exemplo, de 5 a 50 dias)\n",
    "moving_averages = []\n",
    "for window in range(5, 51):\n",
    "    moving_averages.append(calculate_moving_average(data, window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_from_moving_average(data, moving_average):\n",
    "    return abs(data['Close'] - moving_average)\n",
    "\n",
    "distance_from_moving_averages = []\n",
    "for moving_average in moving_averages:\n",
    "    distance_from_moving_averages.append(calculate_distance_from_moving_average(data, moving_average))\n",
    "\n",
    "# Vamos calcular a média das distâncias para cada período\n",
    "mean_distances = [dist.mean() for dist in distance_from_moving_averages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor média móvel é de 5 dias.\n"
     ]
    }
   ],
   "source": [
    "best_window = mean_distances.index(min(mean_distances)) + 5  # +5 pois começamos a partir da janela 5\n",
    "\n",
    "print(f'A melhor média móvel é de {best_window} dias.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor média móvel é de 50 dias, com MSE de -105.27.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Definindo a função para calcular a distância da média móvel simples\n",
    "def calculate_distance_from_simple_moving_average(data, window):\n",
    "    moving_average = data['Close'].rolling(window=window).mean()\n",
    "    return abs(data['Close'] - moving_average)\n",
    "\n",
    "# Criação de um array de períodos de média móvel a serem testados\n",
    "window_sizes = np.arange(5, 51)\n",
    "\n",
    "# Preparação dos dados para validação cruzada\n",
    "X = data[['Close']]\n",
    "y = data['Close']\n",
    "\n",
    "# Definindo o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Inicializando as listas para armazenar os resultados\n",
    "best_window = None\n",
    "best_mse = float('inf')\n",
    "mse_values = []\n",
    "\n",
    "# Realizando a busca pelo melhor período de média móvel\n",
    "for window in window_sizes:\n",
    "    mse = -np.mean(calculate_distance_from_simple_moving_average(data, window)**2)\n",
    "    mse_values.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_window = window\n",
    "\n",
    "print(f\"A melhor média móvel é de {best_window} dias, com MSE de {best_mse:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Close  Buy_Signal  Sell_Signal  PnL  Cumulative_Return\n",
      "Date                                                                   \n",
      "2022-12-16  134.509995           0           -1 -0.0           2.397015\n",
      "2022-12-19  132.369995           0           -1 -0.0           2.397015\n",
      "2022-12-20  132.300003           0           -1 -0.0           2.397015\n",
      "2022-12-21  135.449997           0           -1  0.0           2.397015\n",
      "2022-12-22  132.229996           0           -1 -0.0           2.397015\n",
      "2022-12-23  131.860001           0           -1 -0.0           2.397015\n",
      "2022-12-27  130.029999           0           -1 -0.0           2.397015\n",
      "2022-12-28  126.040001           0           -1 -0.0           2.397015\n",
      "2022-12-29  129.610001           0           -1  0.0           2.397015\n",
      "2022-12-30  129.929993           0           -1  NaN                NaN\n"
     ]
    }
   ],
   "source": [
    "# Calculando a melhor média móvel com o período encontrado pelo GridSearch\n",
    "best_moving_average = data['Close'].rolling(window=best_window).mean()\n",
    "\n",
    "# Criando colunas para sinal de compra (1), sinal de venda (-1) e sinal neutro (0)\n",
    "data['Buy_Signal'] = np.where(data['Close'] > best_moving_average, 1, 0)\n",
    "data['Sell_Signal'] = np.where(data['Close'] < best_moving_average, -1, 0)\n",
    "\n",
    "# Calculando o lucro e a perda (PnL) da estratégia\n",
    "data['PnL'] = data['Close'].pct_change() * data['Buy_Signal'].shift(-1)\n",
    "\n",
    "# Calculando o retorno cumulativo\n",
    "data['Cumulative_Return'] = (1 + data['PnL']).cumprod()\n",
    "\n",
    "# Visualizando os resultados\n",
    "print(data[['Close', 'Buy_Signal', 'Sell_Signal', 'PnL', 'Cumulative_Return']].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retorno anualizado: nan%\n",
      "Índice de Sharpe: 0.14\n",
      "Drawdown máximo: -11.03%\n"
     ]
    }
   ],
   "source": [
    "# Cálculo do retorno anualizado\n",
    "days_per_year = 252  # Supondo que há 252 dias úteis em um ano\n",
    "total_trading_days = data['PnL'].count()\n",
    "annualized_return = ((data['Cumulative_Return'].iloc[-1]) ** (days_per_year / total_trading_days)) - 1\n",
    "\n",
    "# Cálculo do risco livre (pode ser ajustado de acordo com a taxa livre de risco atual)\n",
    "risk_free_rate = 0.03  # Exemplo: 3% ao ano\n",
    "\n",
    "# Cálculo do índice de Sharpe\n",
    "daily_returns = data['PnL']\n",
    "daily_risk_free_rate = (1 + risk_free_rate) ** (1 / days_per_year) - 1\n",
    "daily_volatility = daily_returns.std()\n",
    "sharpe_ratio = (daily_returns.mean() - daily_risk_free_rate) / daily_volatility\n",
    "\n",
    "# Cálculo do drawdown máximo\n",
    "cumulative_returns = data['Cumulative_Return']\n",
    "previous_peaks = cumulative_returns.cummax()\n",
    "drawdowns = cumulative_returns / previous_peaks - 1\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "# Visualizando as métricas\n",
    "print(f\"Retorno anualizado: {annualized_return:.2%}\")\n",
    "print(f\"Índice de Sharpe: {sharpe_ratio:.2f}\")\n",
    "print(f\"Drawdown máximo: {max_drawdown:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.72\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.62      0.74        65\n",
      "         1.0       0.57      0.92      0.70        36\n",
      "\n",
      "    accuracy                           0.72       101\n",
      "   macro avg       0.75      0.77      0.72       101\n",
      "weighted avg       0.80      0.72      0.73       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Preparação dos dados para o modelo de machine learning\n",
    "X = data[['Close']].shift(1).dropna()  # Usamos o preço de fechamento do dia anterior como feature\n",
    "y = data['Buy_Signal'].shift(-1).dropna()  # O sinal de compra do próximo dia é o rótulo\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Criação e treinamento do modelo de Regressão Logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_output = classification_report(y_test, y_pred)\n",
    "\n",
    "# Visualizando os resultados\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo SVM: 0.72\n",
      "Relatório de Classificação do modelo SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.63      0.75        65\n",
      "         1.0       0.57      0.89      0.70        36\n",
      "\n",
      "    accuracy                           0.72       101\n",
      "   macro avg       0.74      0.76      0.72       101\n",
      "weighted avg       0.79      0.72      0.73       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Criação e treinamento do modelo SVM\n",
    "model_svm = SVC(kernel='linear', C=1.0)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_report_output_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Visualizando os resultados do modelo SVM\n",
    "print(f\"Acurácia do modelo SVM: {accuracy_svm:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo SVM:\\n\", classification_report_output_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Erro Médio Absoluto do modelo de Rede Neural: 1.00\n",
      "Erro Médio Quadrático do modelo de Rede Neural: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo de Rede Neural\n",
    "model_nn = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(1,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='mean_squared_error')  # Usando MSE para regressão\n",
    "model_nn.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_nn = model_nn.predict(X_test)\n",
    "\n",
    "# Calculando as métricas de regressão\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "mse_nn = mean_squared_error(y_test, y_pred_nn)\n",
    "\n",
    "# Visualizando os resultados do modelo de Rede Neural\n",
    "print(f\"Erro Médio Absoluto do modelo de Rede Neural: {mae_nn:.2f}\")\n",
    "print(f\"Erro Médio Quadrático do modelo de Rede Neural: {mse_nn:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro Médio Absoluto do modelo ARIMA: 165.42\n",
      "Erro Médio Quadrático do modelo ARIMA: 27366.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo ARIMA\n",
    "model_arima = ARIMA(X_train, order=(5, 1, 0))  # Ordem (p, d, q) ajustável conforme necessário\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_arima = model_arima_fit.forecast(steps=len(X_test))\n",
    "\n",
    "# Calculando as métricas de regressão\n",
    "mae_arima = mean_absolute_error(y_test, y_pred_arima)\n",
    "mse_arima = mean_squared_error(y_test, y_pred_arima)\n",
    "\n",
    "# Visualizando os resultados do modelo ARIMA\n",
    "print(f\"Erro Médio Absoluto do modelo ARIMA: {mae_arima:.2f}\")\n",
    "print(f\"Erro Médio Quadrático do modelo ARIMA: {mse_arima:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n",
      "Erro Médio Absoluto do modelo LSTM: 1.01\n",
      "Erro Médio Quadrático do modelo LSTM: 1.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Preparação dos dados para o modelo LSTM\n",
    "X_train_lstm = X_train.values.reshape(-1, 1, 1)\n",
    "X_test_lstm = X_test.values.reshape(-1, 1, 1)\n",
    "\n",
    "# Criação e treinamento do modelo LSTM\n",
    "model_lstm = Sequential([\n",
    "    LSTM(64, input_shape=(1, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')  # Usando MSE para regressão\n",
    "model_lstm.fit(X_train_lstm, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_lstm = model_lstm.predict(X_test_lstm)\n",
    "\n",
    "# Calculando as métricas de regressão\n",
    "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
    "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
    "\n",
    "# Visualizando os resultados do modelo LSTM\n",
    "print(f\"Erro Médio Absoluto do modelo LSTM: {mae_lstm:.2f}\")\n",
    "print(f\"Erro Médio Quadrático do modelo LSTM: {mse_lstm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.action_space = gym.spaces.Discrete(3)  # 0: não fazer nada, 1: comprar, 2: vender\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.profit = 0\n",
    "        self.holdings = 0\n",
    "        self.initial_balance = 1000  # Defina o saldo inicial desejado\n",
    "        self.balance = self.initial_balance\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return np.array([self.data['Close'].iloc[self.current_step] / self.data['Close'].max()])\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        if action == 1:  # Comprar\n",
    "            if self.holdings == 0:\n",
    "                self.holdings = self.balance / self.data['Close'].iloc[self.current_step]\n",
    "                self.balance = 0\n",
    "\n",
    "        elif action == 2:  # Vender\n",
    "            if self.holdings > 0:\n",
    "                self.balance = self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "                self.holdings = 0\n",
    "\n",
    "        # Calcular a recompensa\n",
    "        current_balance = self.balance + self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "        self.profit = (current_balance - self.initial_balance) / self.initial_balance\n",
    "\n",
    "        # Verificar se o episódio terminou (pode adicionar outras condições de término)\n",
    "        done = self.current_step == len(self.data) - 1\n",
    "\n",
    "        # Definir a recompensa\n",
    "        if done:\n",
    "            reward = self.profit\n",
    "        else:\n",
    "            reward = self.profit - 0.001  # Penalidade diária para incentivar ações mais curtas\n",
    "\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Criação do ambiente de trading\n",
    "env = TradingEnv(data)\n",
    "\n",
    "\n",
    "# Implementação do algoritmo Q-Learning (com a correção do índice do estado)\n",
    "def q_learning(env, num_episodes=100):\n",
    "    q_table = np.zeros((len(env.observation_space.high), env.action_space.n))\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Converter o estado (observation) para um índice inteiro\n",
    "            state_idx = int(state[0] * len(q_table))  # Usar state[0] para obter o valor único do estado\n",
    "\n",
    "            action = np.argmax(q_table[state_idx])\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Converter o novo estado (new_state) para um índice inteiro\n",
    "            new_state_idx = int(new_state[0] * len(q_table))  # Usar new_state[0] para obter o valor único do novo estado\n",
    "\n",
    "            # Atualizar a tabela Q\n",
    "            q_table[state_idx, action] = (1 - 0.1) * q_table[state_idx, action] + 0.1 * (reward + 0.9 * np.max(q_table[new_state_idx]))\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "q_learning(env)\n",
    "\n",
    "# Teste da estratégia treinada\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state])\n",
    "    state, _, done, _ = env.step(action)\n",
    "\n",
    "final_profit = env.profit\n",
    "print(f\"Lucro final da estratégia: {final_profit:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "Erro Médio Absoluto do modelo LSTM: 2.59\n",
      "Erro Médio Quadrático do modelo LSTM: 11.67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data[['Close']])\n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - 1):\n",
    "    X.append(data_scaled[i])\n",
    "    y.append(data_scaled[i + 1][0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape dos dados para o formato [amostras, tempo, características]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Criação e treinamento do modelo LSTM\n",
    "model_lstm = Sequential([\n",
    "    LSTM(64, input_shape=(1, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Transformando as previsões para a escala original\n",
    "y_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculando as métricas de regressão\n",
    "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
    "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
    "\n",
    "# Visualizando os resultados do modelo LSTM\n",
    "print(f\"Erro Médio Absoluto do modelo LSTM: {mae_lstm:.2f}\")\n",
    "print(f\"Erro Médio Quadrático do modelo LSTM: {mse_lstm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Erro Médio Absoluto do modelo CNN: 3.12\n",
      "Erro Médio Quadrático do modelo CNN: 15.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data[['Close']])\n",
    "X, y = [], []\n",
    "look_back = 10  # Defina o tamanho da janela temporal\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i + look_back])\n",
    "    y.append(data_scaled[i + look_back])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo CNN\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(look_back, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_cnn.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_cnn = model_cnn.predict(X_test)\n",
    "\n",
    "# Transformando as previsões para a escala original\n",
    "y_pred_cnn = scaler.inverse_transform(y_pred_cnn)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculando as métricas de regressão\n",
    "mae_cnn = mean_absolute_error(y_test, y_pred_cnn)\n",
    "mse_cnn = mean_squared_error(y_test, y_pred_cnn)\n",
    "\n",
    "# Visualizando os resultados do modelo CNN\n",
    "print(f\"Erro Médio Absoluto do modelo CNN: {mae_cnn:.2f}\")\n",
    "print(f\"Erro Médio Quadrático do modelo CNN: {mse_cnn:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo XGBoost: 0.47\n",
      "Relatório de Classificação do modelo XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.33      0.41        57\n",
      "           1       0.42      0.64      0.51        44\n",
      "\n",
      "    accuracy                           0.47       101\n",
      "   macro avg       0.48      0.48      0.46       101\n",
      "weighted avg       0.49      0.47      0.45       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)  # Substituir os valores -1 por 0\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo XGBoost\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "classification_report_output_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "# Visualizando os resultados do modelo XGBoost\n",
    "print(f\"Acurácia do modelo XGBoost: {accuracy_xgb:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo XGBoost:\\n\", classification_report_output_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest: 0.45\n",
      "Relatório de Classificação do modelo Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.37      0.43        57\n",
      "           1       0.40      0.55      0.46        44\n",
      "\n",
      "    accuracy                           0.45       101\n",
      "   macro avg       0.46      0.46      0.45       101\n",
      "weighted avg       0.46      0.45      0.44       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo Random Forest\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_report_output_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Visualizando os resultados do modelo Random Forest\n",
    "print(f\"Acurácia do modelo Random Forest: {accuracy_rf:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo Random Forest:\\n\", classification_report_output_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Ajustar o tamanho do conjunto de teste para permitir a criação de sequências de tamanho 10\n",
    "look_back = 10\n",
    "num_samples_test = len(X_test)\n",
    "num_sequences = num_samples_test - look_back + 1\n",
    "X_test_new = np.zeros((num_sequences, look_back, 1))\n",
    "y_test_new = np.zeros(num_sequences)\n",
    "\n",
    "for i in range(num_sequences):\n",
    "    X_test_new[i] = X_test[i:i+look_back].reshape(look_back, 1)\n",
    "    y_test_new[i] = y_test[i+look_back-1]\n",
    "\n",
    "X_test = X_test_new\n",
    "y_test = y_test_new\n",
    "\n",
    "# Criação e treinamento do modelo híbrido LSTM + CNN\n",
    "model_hybrid = Sequential([\n",
    "    LSTM(64, input_shape=(look_back, 1), return_sequences=True),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_hybrid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_hybrid.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_hybrid = model_hybrid.predict_classes(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo híbrido LSTM + CNN\n",
    "accuracy_hybrid = accuracy_score(y_test, y_pred_hybrid)\n",
    "classification_report_output_hybrid = classification_report(y_test, y_pred_hybrid)\n",
    "\n",
    "# Visualizando os resultados do modelo híbrido LSTM + CNN\n",
    "print(f\"Acurácia do modelo híbrido LSTM + CNN: {accuracy_hybrid:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo híbrido LSTM + CNN:\\n\", classification_report_output_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.action_space = spaces.Discrete(3)  # 0: não fazer nada, 1: comprar, 2: vender\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.profit = 0\n",
    "        self.holdings = 0\n",
    "        self.initial_balance = 1000  # Defina o saldo inicial desejado\n",
    "        self.balance = self.initial_balance\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return np.array([self.data['Close'].iloc[self.current_step] / self.data['Close'].max()])\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        if action == 1:  # Comprar\n",
    "            if self.holdings == 0:\n",
    "                self.holdings = self.balance / self.data['Close'].iloc[self.current_step]\n",
    "                self.balance = 0\n",
    "\n",
    "        elif action == 2:  # Vender\n",
    "            if self.holdings > 0:\n",
    "                self.balance = self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "                self.holdings = 0\n",
    "\n",
    "        # Calcular a recompensa\n",
    "        current_balance = self.balance + self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "        self.profit = (current_balance - self.initial_balance) / self.initial_balance\n",
    "\n",
    "        # Verificar se o episódio terminou (pode adicionar outras condições de término)\n",
    "        done = self.current_step == len(self.data) - 1\n",
    "\n",
    "        # Definir a recompensa\n",
    "        if done:\n",
    "            reward = self.profit\n",
    "        else:\n",
    "            reward = self.profit - 0.001  # Penalidade diária para incentivar ações mais curtas\n",
    "\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Criação do ambiente de trading\n",
    "env = TradingEnv(data)\n",
    "\n",
    "# Implementação do algoritmo Deep Q-Network (DQN)\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Fator de desconto\n",
    "        self.epsilon = 1.0  # Probabilidade de exploração inicial\n",
    "        self.epsilon_decay = 0.995  # Taxa de decaimento da probabilidade de exploração\n",
    "        self.epsilon_min = 0.01  # Probabilidade mínima de exploração\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Configuração do agente DQN\n",
    "state_size = 1\n",
    "action_size = 3\n",
    "batch_size = 32\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# Treinamento do agente DQN\n",
    "for e in range(100):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"Época: {}/{}, Lucro: {:.2f}\"\n",
    "                  .format(e, 100, env.profit))\n",
    "            break\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "# Teste da estratégia aprendida\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, state_size])\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "final_profit = env.profit\n",
    "print(f\"Lucro final da estratégia: {final_profit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
