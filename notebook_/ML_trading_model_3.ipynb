{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "data = pd.read_csv('data_/TSLA.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>22.366667</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.098000</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>81493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>23.025999</td>\n",
       "      <td>22.119333</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>90846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>22.806000</td>\n",
       "      <td>23.227333</td>\n",
       "      <td>22.584667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>75586500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>22.825333</td>\n",
       "      <td>22.833332</td>\n",
       "      <td>22.266666</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>78709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>22.333332</td>\n",
       "      <td>23.253332</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>90849000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0 2019-01-09  22.366667  22.900000  22.098000  22.568666  22.568666  81493500\n",
       "1 2019-01-10  22.293333  23.025999  22.119333  22.997999  22.997999  90846000\n",
       "2 2019-01-11  22.806000  23.227333  22.584667  23.150667  23.150667  75586500\n",
       "3 2019-01-14  22.825333  22.833332  22.266666  22.293333  22.293333  78709500\n",
       "4 2019-01-15  22.333332  23.253332  22.299999  22.962000  22.962000  90849000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rótulos para classificação\n",
    "data['Return'] = data['Close'].pct_change().shift(-1)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_return(row):\n",
    "    if row['Return'] > 0.01:\n",
    "        return 0\n",
    "    elif row['Return'] < -0.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "data['Label'] = data.apply(label_return, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       2\n",
       "2       1\n",
       "3       0\n",
       "4       2\n",
       "       ..\n",
       "1106    0\n",
       "1107    0\n",
       "1108    0\n",
       "1109    0\n",
       "1110    0\n",
       "Name: Label, Length: 1111, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar o fechamento, máxima e mínima das ações\n",
    "input_data = data[['Close', 'High', 'Low']].values\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar sequências de dados\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data['Label'].iloc[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>22.366667</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.098000</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>81493500</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>23.025999</td>\n",
       "      <td>22.119333</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>90846000</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>22.806000</td>\n",
       "      <td>23.227333</td>\n",
       "      <td>22.584667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>75586500</td>\n",
       "      <td>-0.037033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>22.825333</td>\n",
       "      <td>22.833332</td>\n",
       "      <td>22.266666</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>78709500</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>22.333332</td>\n",
       "      <td>23.253332</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>90849000</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close    Volume  \\\n",
       "0 2019-01-09  22.366667  22.900000  22.098000  22.568666  22.568666  81493500   \n",
       "1 2019-01-10  22.293333  23.025999  22.119333  22.997999  22.997999  90846000   \n",
       "2 2019-01-11  22.806000  23.227333  22.584667  23.150667  23.150667  75586500   \n",
       "3 2019-01-14  22.825333  22.833332  22.266666  22.293333  22.293333  78709500   \n",
       "4 2019-01-15  22.333332  23.253332  22.299999  22.962000  22.962000  90849000   \n",
       "\n",
       "     Return  Label  \n",
       "0  0.019023      0  \n",
       "1  0.006638      2  \n",
       "2 -0.037033      1  \n",
       "3  0.029994      0  \n",
       "4  0.004703      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>22.366667</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.098000</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>81493500</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>23.025999</td>\n",
       "      <td>22.119333</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>90846000</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>22.806000</td>\n",
       "      <td>23.227333</td>\n",
       "      <td>22.584667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>75586500</td>\n",
       "      <td>-0.037033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>22.825333</td>\n",
       "      <td>22.833332</td>\n",
       "      <td>22.266666</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>78709500</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>22.333332</td>\n",
       "      <td>23.253332</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>90849000</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1106</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>202.589996</td>\n",
       "      <td>209.800003</td>\n",
       "      <td>199.369995</td>\n",
       "      <td>207.520004</td>\n",
       "      <td>207.520004</td>\n",
       "      <td>148029900</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1107</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>210.149994</td>\n",
       "      <td>217.250000</td>\n",
       "      <td>209.750000</td>\n",
       "      <td>213.970001</td>\n",
       "      <td>213.970001</td>\n",
       "      <td>164129000</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1108</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>217.800003</td>\n",
       "      <td>221.289993</td>\n",
       "      <td>214.520004</td>\n",
       "      <td>217.610001</td>\n",
       "      <td>217.610001</td>\n",
       "      <td>151143100</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>216.139999</td>\n",
       "      <td>221.910004</td>\n",
       "      <td>212.529999</td>\n",
       "      <td>221.309998</td>\n",
       "      <td>221.309998</td>\n",
       "      <td>146911600</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.830002</td>\n",
       "      <td>223.199997</td>\n",
       "      <td>224.570007</td>\n",
       "      <td>224.570007</td>\n",
       "      <td>185710800</td>\n",
       "      <td>0.045821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1111 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       Date        Open        High         Low       Close  \\\n",
       "0         0 2019-01-09   22.366667   22.900000   22.098000   22.568666   \n",
       "1         1 2019-01-10   22.293333   23.025999   22.119333   22.997999   \n",
       "2         2 2019-01-11   22.806000   23.227333   22.584667   23.150667   \n",
       "3         3 2019-01-14   22.825333   22.833332   22.266666   22.293333   \n",
       "4         4 2019-01-15   22.333332   23.253332   22.299999   22.962000   \n",
       "...     ...        ...         ...         ...         ...         ...   \n",
       "1106   1106 2023-06-01  202.589996  209.800003  199.369995  207.520004   \n",
       "1107   1107 2023-06-02  210.149994  217.250000  209.750000  213.970001   \n",
       "1108   1108 2023-06-05  217.800003  221.289993  214.520004  217.610001   \n",
       "1109   1109 2023-06-06  216.139999  221.910004  212.529999  221.309998   \n",
       "1110   1110 2023-06-07  228.000000  230.830002  223.199997  224.570007   \n",
       "\n",
       "       Adj Close     Volume    Return  Label  \n",
       "0      22.568666   81493500  0.019023      0  \n",
       "1      22.997999   90846000  0.006638      2  \n",
       "2      23.150667   75586500 -0.037033      1  \n",
       "3      22.293333   78709500  0.029994      0  \n",
       "4      22.962000   90849000  0.004703      2  \n",
       "...          ...        ...       ...    ...  \n",
       "1106  207.520004  148029900  0.031081      0  \n",
       "1107  213.970001  164129000  0.017012      0  \n",
       "1108  217.610001  151143100  0.017003      0  \n",
       "1109  221.309998  146911600  0.014731      0  \n",
       "1110  224.570007  185710800  0.045821      0  \n",
       "\n",
       "[1111 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Return',\n",
       "       'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.366667</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.098000</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>22.568666</td>\n",
       "      <td>81493500</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.293333</td>\n",
       "      <td>23.025999</td>\n",
       "      <td>22.119333</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>22.997999</td>\n",
       "      <td>90846000</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.806000</td>\n",
       "      <td>23.227333</td>\n",
       "      <td>22.584667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>23.150667</td>\n",
       "      <td>75586500</td>\n",
       "      <td>-0.037033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.825333</td>\n",
       "      <td>22.833332</td>\n",
       "      <td>22.266666</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>22.293333</td>\n",
       "      <td>78709500</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.333332</td>\n",
       "      <td>23.253332</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>22.962000</td>\n",
       "      <td>90849000</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>202.589996</td>\n",
       "      <td>209.800003</td>\n",
       "      <td>199.369995</td>\n",
       "      <td>207.520004</td>\n",
       "      <td>207.520004</td>\n",
       "      <td>148029900</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>210.149994</td>\n",
       "      <td>217.250000</td>\n",
       "      <td>209.750000</td>\n",
       "      <td>213.970001</td>\n",
       "      <td>213.970001</td>\n",
       "      <td>164129000</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>217.800003</td>\n",
       "      <td>221.289993</td>\n",
       "      <td>214.520004</td>\n",
       "      <td>217.610001</td>\n",
       "      <td>217.610001</td>\n",
       "      <td>151143100</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>216.139999</td>\n",
       "      <td>221.910004</td>\n",
       "      <td>212.529999</td>\n",
       "      <td>221.309998</td>\n",
       "      <td>221.309998</td>\n",
       "      <td>146911600</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>228.000000</td>\n",
       "      <td>230.830002</td>\n",
       "      <td>223.199997</td>\n",
       "      <td>224.570007</td>\n",
       "      <td>224.570007</td>\n",
       "      <td>185710800</td>\n",
       "      <td>0.045821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1111 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High         Low       Close   Adj Close     Volume  \\\n",
       "0      22.366667   22.900000   22.098000   22.568666   22.568666   81493500   \n",
       "1      22.293333   23.025999   22.119333   22.997999   22.997999   90846000   \n",
       "2      22.806000   23.227333   22.584667   23.150667   23.150667   75586500   \n",
       "3      22.825333   22.833332   22.266666   22.293333   22.293333   78709500   \n",
       "4      22.333332   23.253332   22.299999   22.962000   22.962000   90849000   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "1106  202.589996  209.800003  199.369995  207.520004  207.520004  148029900   \n",
       "1107  210.149994  217.250000  209.750000  213.970001  213.970001  164129000   \n",
       "1108  217.800003  221.289993  214.520004  217.610001  217.610001  151143100   \n",
       "1109  216.139999  221.910004  212.529999  221.309998  221.309998  146911600   \n",
       "1110  228.000000  230.830002  223.199997  224.570007  224.570007  185710800   \n",
       "\n",
       "        Return  Label  \n",
       "0     0.019023      0  \n",
       "1     0.006638      2  \n",
       "2    -0.037033      1  \n",
       "3     0.029994      0  \n",
       "4     0.004703      2  \n",
       "...        ...    ...  \n",
       "1106  0.031081      0  \n",
       "1107  0.017012      0  \n",
       "1108  0.017003      0  \n",
       "1109  0.014731      0  \n",
       "1110  0.045821      0  \n",
       "\n",
       "[1111 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 10\n",
    "\n",
    "X, y = create_sequences(data, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o modelo RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', \n",
    "                    input_shape=(X_train.shape[1], \n",
    "                                 X_train.shape[2])))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.23666668e+01  2.28999996e+01  2.20979996e+01 ...  8.14935000e+07\n",
      "    1.90233984e-02  0.00000000e+00]\n",
      "  [ 2.22933331e+01  2.30259991e+01  2.21193333e+01 ...  9.08460000e+07\n",
      "    6.63831658e-03  2.00000000e+00]\n",
      "  [ 2.28059998e+01  2.32273331e+01  2.25846672e+01 ...  7.55865000e+07\n",
      "   -3.70328047e-02  1.00000000e+00]\n",
      "  ...\n",
      "  [ 2.15333328e+01  2.18086662e+01  1.99820004e+01 ...  3.62262000e+08\n",
      "   -1.10501400e-02  1.00000000e+00]\n",
      "  [ 2.03213329e+01  2.05333328e+01  1.97000008e+01 ...  1.81000500e+08\n",
      "   -3.79030995e-02  1.00000000e+00]\n",
      "  [ 1.95000000e+01  1.96333332e+01  1.87793331e+01 ...  1.87950000e+08\n",
      "    1.36305226e-02  0.00000000e+00]]\n",
      "\n",
      " [[ 2.22933331e+01  2.30259991e+01  2.21193333e+01 ...  9.08460000e+07\n",
      "    6.63831658e-03  2.00000000e+00]\n",
      "  [ 2.28059998e+01  2.32273331e+01  2.25846672e+01 ...  7.55865000e+07\n",
      "   -3.70328047e-02  1.00000000e+00]\n",
      "  [ 2.28253326e+01  2.28333321e+01  2.22666664e+01 ...  7.87095000e+07\n",
      "    2.99940273e-02  0.00000000e+00]\n",
      "  ...\n",
      "  [ 2.03213329e+01  2.05333328e+01  1.97000008e+01 ...  1.81000500e+08\n",
      "   -3.79030995e-02  1.00000000e+00]\n",
      "  [ 1.95000000e+01  1.96333332e+01  1.87793331e+01 ...  1.87950000e+08\n",
      "    1.36305226e-02  0.00000000e+00]\n",
      "  [ 1.88686676e+01  1.95786667e+01  1.86186676e+01 ...  1.20183000e+08\n",
      "    1.89702378e-02  0.00000000e+00]]\n",
      "\n",
      " [[ 2.28059998e+01  2.32273331e+01  2.25846672e+01 ...  7.55865000e+07\n",
      "   -3.70328047e-02  1.00000000e+00]\n",
      "  [ 2.28253326e+01  2.28333321e+01  2.22666664e+01 ...  7.87095000e+07\n",
      "    2.99940273e-02  0.00000000e+00]\n",
      "  [ 2.23333321e+01  2.32533321e+01  2.22999992e+01 ...  9.08490000e+07\n",
      "    4.70341443e-03  2.00000000e+00]\n",
      "  ...\n",
      "  [ 1.95000000e+01  1.96333332e+01  1.87793331e+01 ...  1.87950000e+08\n",
      "    1.36305226e-02  0.00000000e+00]\n",
      "  [ 1.88686676e+01  1.95786667e+01  1.86186676e+01 ...  1.20183000e+08\n",
      "    1.89702378e-02  0.00000000e+00]\n",
      "  [ 1.96259995e+01  1.99013329e+01  1.93033333e+01 ...  1.08744000e+08\n",
      "   -2.22195446e-03  2.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.23000000e+02  2.33146667e+02  2.16166672e+02 ...  8.45811000e+07\n",
      "   -5.72080200e-03  2.00000000e+00]\n",
      "  [ 2.30779999e+02  2.34563339e+02  2.27186661e+02 ...  7.18536000e+07\n",
      "    5.52790449e-02  0.00000000e+00]\n",
      "  [ 2.33919998e+02  2.45363327e+02  2.32210007e+02 ...  8.19306000e+07\n",
      "    2.54351697e-02  0.00000000e+00]\n",
      "  ...\n",
      "  [ 2.34896667e+02  2.38653336e+02  2.29333328e+02 ...  7.85574000e+07\n",
      "    7.35723154e-03  2.00000000e+00]\n",
      "  [ 2.40000000e+02  2.43623337e+02  2.36889999e+02 ...  6.96831000e+07\n",
      "    1.99942681e-03  2.00000000e+00]\n",
      "  [ 2.44936661e+02  2.50516663e+02  2.39603333e+02 ...  8.25375000e+07\n",
      "    2.07167182e-02  0.00000000e+00]]\n",
      "\n",
      " [[ 2.30779999e+02  2.34563339e+02  2.27186661e+02 ...  7.18536000e+07\n",
      "    5.52790449e-02  0.00000000e+00]\n",
      "  [ 2.33919998e+02  2.45363327e+02  2.32210007e+02 ...  8.19306000e+07\n",
      "    2.54351697e-02  0.00000000e+00]\n",
      "  [ 2.42333328e+02  2.54979996e+02  2.41160004e+02 ...  1.01854200e+08\n",
      "   -6.54800595e-02  1.00000000e+00]\n",
      "  ...\n",
      "  [ 2.40000000e+02  2.43623337e+02  2.36889999e+02 ...  6.96831000e+07\n",
      "    1.99942681e-03  2.00000000e+00]\n",
      "  [ 2.44936661e+02  2.50516663e+02  2.39603333e+02 ...  8.25375000e+07\n",
      "    2.07167182e-02  0.00000000e+00]\n",
      "  [ 2.45000000e+02  2.47139999e+02  2.36976669e+02 ...  8.08902000e+07\n",
      "    8.02346447e-03  2.00000000e+00]]\n",
      "\n",
      " [[ 2.33919998e+02  2.45363327e+02  2.32210007e+02 ...  8.19306000e+07\n",
      "    2.54351697e-02  0.00000000e+00]\n",
      "  [ 2.42333328e+02  2.54979996e+02  2.41160004e+02 ...  1.01854200e+08\n",
      "   -6.54800595e-02  1.00000000e+00]\n",
      "  [ 2.52103333e+02  2.53063339e+02  2.33626663e+02 ...  9.92412000e+07\n",
      "   -5.43361164e-03  2.00000000e+00]\n",
      "  ...\n",
      "  [ 2.44936661e+02  2.50516663e+02  2.39603333e+02 ...  8.25375000e+07\n",
      "    2.07167182e-02  0.00000000e+00]\n",
      "  [ 2.45000000e+02  2.47139999e+02  2.36976669e+02 ...  8.08902000e+07\n",
      "    8.02346447e-03  2.00000000e+00]\n",
      "  [ 2.46783340e+02  2.50663330e+02  2.43483337e+02 ...  8.88642000e+07\n",
      "    9.78047072e-02  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 34ms/step - loss: 59151628.0000 - accuracy: 0.3045 - val_loss: 16732180.0000 - val_accuracy: 0.3710\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 12571349.0000 - accuracy: 0.3443 - val_loss: 7530064.0000 - val_accuracy: 0.2579\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 6533622.5000 - accuracy: 0.3432 - val_loss: 2467632.7500 - val_accuracy: 0.3439\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3486517.0000 - accuracy: 0.3477 - val_loss: 1081900.5000 - val_accuracy: 0.4118\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2061074.1250 - accuracy: 0.3602 - val_loss: 654380.7500 - val_accuracy: 0.3575\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1429519.8750 - accuracy: 0.3636 - val_loss: 325487.5625 - val_accuracy: 0.3846\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1035745.6250 - accuracy: 0.3614 - val_loss: 560257.0625 - val_accuracy: 0.3213\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 845716.1250 - accuracy: 0.3614 - val_loss: 396419.5625 - val_accuracy: 0.3529\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 674777.8750 - accuracy: 0.3852 - val_loss: 378466.7812 - val_accuracy: 0.3710\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 554334.6875 - accuracy: 0.3966 - val_loss: 287323.4375 - val_accuracy: 0.3484\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 530929.0000 - accuracy: 0.3852 - val_loss: 314803.5625 - val_accuracy: 0.3348\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 503566.6562 - accuracy: 0.3784 - val_loss: 480565.7812 - val_accuracy: 0.3439\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 475519.4062 - accuracy: 0.3875 - val_loss: 225532.3125 - val_accuracy: 0.3710\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 371760.4062 - accuracy: 0.3773 - val_loss: 228400.3125 - val_accuracy: 0.4163\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 389946.2812 - accuracy: 0.3568 - val_loss: 249384.5312 - val_accuracy: 0.2353\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 373021.3750 - accuracy: 0.3864 - val_loss: 147136.2344 - val_accuracy: 0.3891\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 294727.2812 - accuracy: 0.3739 - val_loss: 134972.3750 - val_accuracy: 0.3439\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 390866.4688 - accuracy: 0.3557 - val_loss: 360381.7812 - val_accuracy: 0.3891\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 369084.8125 - accuracy: 0.3966 - val_loss: 240980.1875 - val_accuracy: 0.3846\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 416679.9062 - accuracy: 0.3773 - val_loss: 324561.4375 - val_accuracy: 0.2398\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 403698.7188 - accuracy: 0.3761 - val_loss: 371490.5938 - val_accuracy: 0.3756\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 350800.9688 - accuracy: 0.3977 - val_loss: 380733.9062 - val_accuracy: 0.3756\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 379322.3125 - accuracy: 0.3795 - val_loss: 285221.8750 - val_accuracy: 0.3529\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 296345.9688 - accuracy: 0.3920 - val_loss: 85480.5781 - val_accuracy: 0.4118\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 332446.1562 - accuracy: 0.3557 - val_loss: 161797.2969 - val_accuracy: 0.4072\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 396419.1250 - accuracy: 0.3966 - val_loss: 340889.1875 - val_accuracy: 0.3032\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 367131.5938 - accuracy: 0.3455 - val_loss: 109195.7266 - val_accuracy: 0.3303\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 363627.3750 - accuracy: 0.3670 - val_loss: 476236.6250 - val_accuracy: 0.3665\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 346335.9688 - accuracy: 0.3727 - val_loss: 226846.9531 - val_accuracy: 0.3756\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 263018.6250 - accuracy: 0.3989 - val_loss: 200746.0625 - val_accuracy: 0.3303\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 271419.9375 - accuracy: 0.4034 - val_loss: 352725.4688 - val_accuracy: 0.3982\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 281487.1875 - accuracy: 0.3898 - val_loss: 143808.2344 - val_accuracy: 0.3937\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 209966.9844 - accuracy: 0.4011 - val_loss: 207290.2969 - val_accuracy: 0.2579\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 293956.0312 - accuracy: 0.3682 - val_loss: 223905.7188 - val_accuracy: 0.3710\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 320894.0312 - accuracy: 0.3795 - val_loss: 179030.2500 - val_accuracy: 0.3937\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 229708.5469 - accuracy: 0.3636 - val_loss: 236346.3125 - val_accuracy: 0.3710\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 253815.7031 - accuracy: 0.3591 - val_loss: 146487.3438 - val_accuracy: 0.3891\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 150795.4531 - accuracy: 0.3886 - val_loss: 255319.1250 - val_accuracy: 0.3801\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 269701.9688 - accuracy: 0.3693 - val_loss: 343057.9688 - val_accuracy: 0.2489\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 287385.2188 - accuracy: 0.3773 - val_loss: 158689.5312 - val_accuracy: 0.3891\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 366964.3125 - accuracy: 0.3659 - val_loss: 296642.7188 - val_accuracy: 0.2489\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 274283.5312 - accuracy: 0.3920 - val_loss: 195415.5781 - val_accuracy: 0.3846\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 234569.0156 - accuracy: 0.3886 - val_loss: 191613.9219 - val_accuracy: 0.3529\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 190763.3281 - accuracy: 0.3920 - val_loss: 246432.5312 - val_accuracy: 0.2308\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 275577.9688 - accuracy: 0.4023 - val_loss: 197525.3906 - val_accuracy: 0.3439\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 449137.6875 - accuracy: 0.4045 - val_loss: 327085.6250 - val_accuracy: 0.3484\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 412090.0000 - accuracy: 0.3886 - val_loss: 337769.0000 - val_accuracy: 0.3710\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 224420.5156 - accuracy: 0.3875 - val_loss: 222818.6406 - val_accuracy: 0.3756\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 226224.8594 - accuracy: 0.3727 - val_loss: 201974.3906 - val_accuracy: 0.2489\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 178071.5625 - accuracy: 0.4000 - val_loss: 72861.5078 - val_accuracy: 0.4525\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 206319.0156 - accuracy: 0.4057 - val_loss: 233417.9688 - val_accuracy: 0.4208\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 252395.0000 - accuracy: 0.3795 - val_loss: 242091.2656 - val_accuracy: 0.2670\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 204912.1406 - accuracy: 0.3693 - val_loss: 176507.0469 - val_accuracy: 0.2534\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 182652.5625 - accuracy: 0.3795 - val_loss: 88490.5625 - val_accuracy: 0.3846\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 193083.4219 - accuracy: 0.3898 - val_loss: 149310.7969 - val_accuracy: 0.3575\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 185495.8125 - accuracy: 0.3875 - val_loss: 174265.0938 - val_accuracy: 0.2670\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 293787.1250 - accuracy: 0.3648 - val_loss: 386435.9688 - val_accuracy: 0.3801\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 397653.1875 - accuracy: 0.3852 - val_loss: 187679.0000 - val_accuracy: 0.3529\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 148002.3438 - accuracy: 0.4239 - val_loss: 190835.4375 - val_accuracy: 0.3801\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 319347.1562 - accuracy: 0.3636 - val_loss: 300051.6875 - val_accuracy: 0.3710\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 292738.0625 - accuracy: 0.3989 - val_loss: 280411.4062 - val_accuracy: 0.2534\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 240124.4531 - accuracy: 0.4057 - val_loss: 37006.0156 - val_accuracy: 0.3982\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 216279.7031 - accuracy: 0.3784 - val_loss: 330384.6562 - val_accuracy: 0.3801\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 232948.4375 - accuracy: 0.3864 - val_loss: 59430.6211 - val_accuracy: 0.4027\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 180386.6562 - accuracy: 0.4159 - val_loss: 173324.7188 - val_accuracy: 0.3801\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 237814.2656 - accuracy: 0.3818 - val_loss: 156715.4688 - val_accuracy: 0.2534\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 253414.9531 - accuracy: 0.3932 - val_loss: 223571.4062 - val_accuracy: 0.2489\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 195046.3594 - accuracy: 0.4091 - val_loss: 134244.7656 - val_accuracy: 0.2353\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 169694.0781 - accuracy: 0.3864 - val_loss: 54372.3164 - val_accuracy: 0.3303\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 147947.4375 - accuracy: 0.4045 - val_loss: 73201.1953 - val_accuracy: 0.2398\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 219205.0000 - accuracy: 0.3784 - val_loss: 277514.5312 - val_accuracy: 0.2489\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 203313.6875 - accuracy: 0.3864 - val_loss: 215634.2969 - val_accuracy: 0.2534\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 184603.2969 - accuracy: 0.3943 - val_loss: 253443.1562 - val_accuracy: 0.2534\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 188761.1250 - accuracy: 0.3920 - val_loss: 233601.7969 - val_accuracy: 0.3756\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 185520.8438 - accuracy: 0.3886 - val_loss: 85312.6328 - val_accuracy: 0.3756\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 117924.4844 - accuracy: 0.4227 - val_loss: 45808.2891 - val_accuracy: 0.4299\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 144589.0781 - accuracy: 0.3807 - val_loss: 302638.6562 - val_accuracy: 0.2489\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 245036.2031 - accuracy: 0.4091 - val_loss: 41797.1406 - val_accuracy: 0.3303\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 176285.6875 - accuracy: 0.3841 - val_loss: 186760.1250 - val_accuracy: 0.3756\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 263024.4062 - accuracy: 0.3898 - val_loss: 518115.3750 - val_accuracy: 0.3801\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 346911.8438 - accuracy: 0.3886 - val_loss: 176704.1406 - val_accuracy: 0.2805\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 199653.8438 - accuracy: 0.4080 - val_loss: 239826.9375 - val_accuracy: 0.3710\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 222715.9844 - accuracy: 0.3909 - val_loss: 174800.9062 - val_accuracy: 0.3756\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 194872.3281 - accuracy: 0.4102 - val_loss: 211919.5156 - val_accuracy: 0.3801\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 153247.6250 - accuracy: 0.4045 - val_loss: 113160.2422 - val_accuracy: 0.4208\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 110033.3672 - accuracy: 0.4148 - val_loss: 109228.1328 - val_accuracy: 0.3846\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 276574.0938 - accuracy: 0.3886 - val_loss: 444873.6562 - val_accuracy: 0.3801\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 301267.5938 - accuracy: 0.3739 - val_loss: 288812.4062 - val_accuracy: 0.3756\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 237929.6719 - accuracy: 0.4034 - val_loss: 385743.4062 - val_accuracy: 0.2489\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 204217.8906 - accuracy: 0.4193 - val_loss: 170453.5000 - val_accuracy: 0.3756\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 199362.5312 - accuracy: 0.3966 - val_loss: 222027.1719 - val_accuracy: 0.3710\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 195545.6875 - accuracy: 0.4148 - val_loss: 166737.5000 - val_accuracy: 0.3710\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 295393.0625 - accuracy: 0.3670 - val_loss: 320637.8750 - val_accuracy: 0.2534\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 201713.2500 - accuracy: 0.3920 - val_loss: 154069.9531 - val_accuracy: 0.3891\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 167066.7812 - accuracy: 0.3682 - val_loss: 190550.7500 - val_accuracy: 0.3665\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 227458.7500 - accuracy: 0.4080 - val_loss: 234490.0312 - val_accuracy: 0.3710\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 348908.8125 - accuracy: 0.3727 - val_loss: 133685.5312 - val_accuracy: 0.3801\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 113186.1719 - accuracy: 0.4318 - val_loss: 126769.8906 - val_accuracy: 0.3846\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 106694.8281 - accuracy: 0.4000 - val_loss: 119904.9141 - val_accuracy: 0.3710\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 161809.9844 - accuracy: 0.3750 - val_loss: 187680.4531 - val_accuracy: 0.3756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b10c798580>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=100, batch_size=64, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.3756\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
