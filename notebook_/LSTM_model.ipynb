{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_/USDJPY_M15.csv', sep='\\t')\n",
    "df = df.rename(columns={'<CLOSE>': 'PrecoAtual',\n",
    "                        '<TICKVOL>': 'Volume',\n",
    "                        '<DATE>': 'Date'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['PrecoAtual', 'Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Media'] = df['PrecoAtual'].rolling(20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'df' é seu DataFrame contendo as colunas 'PrecoAtual', 'Volume', 'Media'\n",
    "# df = pd.read_csv('seu_arquivo_de_dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(df[['PrecoAtual', 'Volume', 'Media']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados de entrada para LSTM\n",
    "\n",
    "def create_dataset(X, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(X[i + time_steps, 0])  # Previsão do próximo preço\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "time_steps = 5\n",
    "X, y = create_dataset(scaled_features, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo LSTM\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(\n",
    "        X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=50,\n",
    "                    batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "predicted_prices = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd[:,][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverter a normalização para os preços reais\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ajustar a função state_creator\n",
    "def state_creator(data, timestep, window_size):\n",
    "    starting_id = timestep - window_size + 1\n",
    "\n",
    "    if starting_id >= 0:\n",
    "        # Adicionar nova_variavel aqui\n",
    "        windowed_data = np.array(data[starting_id:timestep + 1])\n",
    "    else:\n",
    "        # Adicionar nova_variavel aqui\n",
    "        windowed_data = np.array(-starting_id *\n",
    "                                 [data[0]] + list(data[0:timestep + 1]))\n",
    "\n",
    "    # Adicionar nova_variavel aqui\n",
    "    nova_variavel = ...  # Lógica para calcular a nova variável com base nos dados\n",
    "\n",
    "    state = []\n",
    "    for i in range(window_size - 1):\n",
    "        state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\n",
    "\n",
    "    # Adicionar nova_variavel ao estado\n",
    "    state.append(nova_variavel)\n",
    "\n",
    "    return np.array([state]), windowed_data\n",
    "\n",
    "# 2. Atualizar o modelo\n",
    "\n",
    "\n",
    "def model_builder(self):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Atualizar a dimensão do estado\n",
    "    model.add(tf.keras.Input(shape=(self.state_size,)))\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=self.action_space, activation=\"linear\"))\n",
    "    model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ajustar a função state_creator\n",
    "def state_creator(data, timestep, window_size):\n",
    "    starting_id = timestep - window_size + 1\n",
    "\n",
    "    if starting_id >= 0:\n",
    "        windowed_data = np.array(data[starting_id:timestep + 1])\n",
    "    else:\n",
    "        windowed_data = np.array(-starting_id *\n",
    "                                 [data[0]] + list(data[0:timestep + 1]))\n",
    "\n",
    "    # Calcular a diferença entre os preços\n",
    "    price_diff = [windowed_data[i + 1] - windowed_data[i]\n",
    "                  for i in range(window_size - 1)]\n",
    "\n",
    "    # Adicionar o volume ao estado\n",
    "    # Você pode ajustar isso para a lógica real de cálculo do volume\n",
    "    volume = windowed_data[-1]\n",
    "    state = price_diff + [volume]\n",
    "\n",
    "    return np.array([state]), windowed_data\n",
    "\n",
    "# 2. Atualizar o modelo\n",
    "\n",
    "\n",
    "def model_builder(self):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Atualizar a dimensão do estado\n",
    "    model.add(tf.keras.Input(shape=(self.state_size,)))\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=self.action_space, activation=\"linear\"))\n",
    "    model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 1: Instalação da bibliotecas\n",
    "\"\"\"\n",
    "!pip uninstall -y tensorflow #Comando necessário, pois o TensorFlow-gpu não desinstala a versão mais recente do Tensorflow, pode gerar conflitos.\n",
    "\n",
    "!pip install tensorflow==2.8.0 #Atualizado 14/03/2022 Algumas bibliotecas ainda não tem compatibilidade com versões acima, favor utilizar somente essa versão.\n",
    "\n",
    "!pip install -q tensorflow-gpu==2.8.0 #Atualizado 14/03/2022 Algumas bibliotecas ainda não tem compatibilidade com versões acima, favor utilizar somente essa versão.\n",
    "\n",
    "!pip install pandas-datareader\n",
    "\n",
    "!pip install -q yfinance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Etapa 2: Importação das bibliotecas\"\"\"\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "from pandas.util.testing import assert_frame_equal  # import alterado\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Etapa 3: Construção da IA para negociação de ações\"\"\"\n",
    "\n",
    "class AI_Trader():\n",
    "\n",
    "  def __init__(self, state_size, action_space = 3, model_name = \"AITrader\"):\n",
    "    self.state_size = state_size\n",
    "    self.action_space = action_space\n",
    "    self.memory = deque(maxlen = 2000)\n",
    "    self.model_name = model_name\n",
    "\n",
    "    self.gamma = 0.95\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_final = 0.01\n",
    "    self.epsilon_decay = 0.995\n",
    "    self.model = self.model_builder()\n",
    "\n",
    "  def model_builder(self):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(self.state_size,)))\n",
    "    model.add(tf.keras.layers.Dense(units = 32, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 64, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 128, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units = self.action_space, activation = \"linear\"))\n",
    "    model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(lr = 0.001))\n",
    "    return model\n",
    "\n",
    "\n",
    "  def trade(self, state):\n",
    "    if random.random() <= self.epsilon:\n",
    "      return random.randrange(self.action_space)\n",
    "\n",
    "    actions = self.model.predict(state[0]) #Atualizado 12/12/2022\n",
    "    return np.argmax(actions[0])\n",
    "\n",
    "  def batch_train(self, batch_size):\n",
    "    batch = []\n",
    "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "      batch.append(self.memory[i])\n",
    "\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "      if not done:\n",
    "        reward = reward + self.gamma * np.amax(self.model.predict(next_state[0]))\n",
    "\n",
    "      target = self.model.predict(state[0]) #Atualizado 12/12/2022\n",
    "      target[0][action] = reward\n",
    "\n",
    "      self.model.fit(state[0], target, epochs=1, verbose=0) #Atualizado 12/12/2022\n",
    "\n",
    "    if self.epsilon > self.epsilon_final:\n",
    "      self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Etapa 4: Pré-processamento da base de dados\n",
    "\n",
    "### Definição de funções auxiliares\n",
    "\n",
    "#### Sigmoid\n",
    "\"\"\"\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid(0.5)\n",
    "\n",
    "\"\"\"#### Formatação de preços\"\"\"\n",
    "\n",
    "def stocks_price_format(n):\n",
    "  if n < 0:\n",
    "    return \"- $ {0:2f}\".format(abs(n))\n",
    "  else:\n",
    "    return \"$ {0:2f}\".format(abs(n))\n",
    "\n",
    "stocks_price_format(100)\n",
    "\n",
    "\"\"\"#### Carregador da base de dados\"\"\"\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "#dataset = data_reader.DataReader(\"AAPL\", data_source = \"yahoo\")\n",
    "dataset = yf.download(\"AAPL\", start='2016-06-02')\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "str(dataset.index[0]).split()[0]\n",
    "\n",
    "dataset.index[-1]\n",
    "\n",
    "dataset['Close']\n",
    "\n",
    "def dataset_loader(stock_name):\n",
    "  #dataset = data_reader.DataReader(stock_name, data_source = \"yahoo\")\n",
    "  dataset = yf.download(stock_name, start='2016-06-02')\n",
    "  start_date = str(dataset.index[0]).split()[0]\n",
    "  end_date = str(dataset.index[-1]).split()[0]\n",
    "  close = dataset['Close']\n",
    "  return close\n",
    "\n",
    "\"\"\"### Criador de estados\"\"\"\n",
    "\n",
    "0 - 5 + 1\n",
    "\n",
    "20 - 5 + 1\n",
    "\n",
    "dataset[16:21]\n",
    "\n",
    "def state_creator(data, timestep, window_size):\n",
    "  starting_id = timestep - window_size + 1\n",
    "\n",
    "  if starting_id >= 0:\n",
    "    # windowed_data = data[starting_id:timestep + 1] # Atualizado 14/03/2022\n",
    "    windowed_data = np.array(data[starting_id:timestep + 1]) # Atualizado 14/03/2022\n",
    "  else:\n",
    "    # windowed_data = - starting_id * [data[0]] + list(data[0:timestep + 1]) # Atualizado 14/03/2022\n",
    "    windowed_data = np.array(- starting_id * [data[0]] + list(data[0:timestep + 1])) # Atualizado 14/03/2022\n",
    "\n",
    "  state = []\n",
    "  for i in range(window_size - 1):\n",
    "    state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\n",
    "\n",
    "  return np.array([state]), windowed_data\n",
    "\n",
    "\"\"\"### Carregando a base de dados\"\"\"\n",
    "\n",
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)\n",
    "\n",
    "s, w = state_creator(data, 0, 5)\n",
    "\n",
    "s\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"## Etapa 5: Treinando a IA\n",
    "\n",
    "### Configuração dos hyper parâmetros\n",
    "\"\"\"\n",
    "\n",
    "window_size = 10\n",
    "episodes = 1000\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1\n",
    "\n",
    "data_samples\n",
    "\n",
    "\"\"\"### Definição do modelo\"\"\"\n",
    "\n",
    "trader = AI_Trader(window_size)\n",
    "\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader(stock_name):\n",
    "  # dataset = data_reader.DataReader(stock_name, data_source = \"yahoo\")\n",
    "  dataset = yf.download(stock_name, start='2021-01-02', end='2022-12-31')\n",
    "  start_date = str(dataset.index[0]).split()[0]\n",
    "  end_date = str(dataset.index[-1]).split()[0]\n",
    "  close = dataset['Close']\n",
    "  return close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 10\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(1, episodes + 1):\n",
    "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "  state = state_creator(data, 0, window_size + 1)\n",
    "  total_profit = 0\n",
    "  trader.inventory = []\n",
    "  for t in tqdm(range(data_samples)):\n",
    "    action = trader.trade(state)\n",
    "    next_state = state_creator(data, t + 1, window_size + 1)\n",
    "    reward = 0\n",
    "\n",
    "    if action == 1:  # Comprando uma ação\n",
    "      trader.inventory.append(data[t])\n",
    "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "    elif action == 2 and len(trader.inventory) > 0:  # Vendendo uma ação\n",
    "      buy_price = trader.inventory.pop(0)\n",
    "\n",
    "      reward = max(data[t] - buy_price, 0)\n",
    "      total_profit += data[t] - buy_price\n",
    "      print(\"AI Trader sold: \", stocks_price_format(\n",
    "          data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price))\n",
    "\n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "\n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "      print(\"########################\")\n",
    "      print(\"Total profit: {}\".format(total_profit))\n",
    "      print(\"########################\")\n",
    "\n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "\n",
    "  if episode % 10 == 0:\n",
    "    trader.model.save(\"ai_trader_{}.h5\".format(episode))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
