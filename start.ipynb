{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados fin\n",
    "import yfinance as yf\n",
    "\n",
    "start = '2021-01-01'\n",
    "end = '2023-01-01'\n",
    "\n",
    "data = yf.download('AAPL', \n",
    "                   start=start,\n",
    "                   end=end)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.to_csv('data_/AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_average(data, window):\n",
    "    return data['Close'].rolling(window=window).mean()\n",
    "\n",
    "# Vamos testar para diferentes períodos de média móvel (por exemplo, de 5 a 50 dias)\n",
    "moving_averages = []\n",
    "for window in range(5, 51):\n",
    "    moving_averages.append(calculate_moving_average(data, window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_from_moving_average(data, moving_average):\n",
    "    return abs(data['Close'] - moving_average)\n",
    "\n",
    "distance_from_moving_averages = []\n",
    "for moving_average in moving_averages:\n",
    "    distance_from_moving_averages.append(calculate_distance_from_moving_average(data, moving_average))\n",
    "\n",
    "# Vamos calcular a média das distâncias para cada período\n",
    "mean_distances = [dist.mean() for dist in distance_from_moving_averages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_window = mean_distances.index(min(mean_distances)) + 5  # +5 pois começamos a partir da janela 5\n",
    "\n",
    "print(f'A melhor média móvel é de {best_window} dias.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Carregando os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Definindo a função para calcular a distância da média móvel simples\n",
    "def calculate_distance_from_simple_moving_average(data, window):\n",
    "    moving_average = data['Close'].rolling(window=window).mean()\n",
    "    return abs(data['Close'] - moving_average)\n",
    "\n",
    "# Criação de um array de períodos de média móvel a serem testados\n",
    "window_sizes = np.arange(5, 51)\n",
    "\n",
    "# Preparação dos dados para validação cruzada\n",
    "X = data[['Close']]\n",
    "y = data['Close']\n",
    "\n",
    "# Definindo o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Definindo os parâmetros a serem testados no GridSearch\n",
    "param_grid = {'window': window_sizes}\n",
    "\n",
    "# Definindo a estratégia de validação cruzada\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Criando o objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Executando a busca pelo melhor período de média móvel\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Extraindo os resultados\n",
    "best_window = grid_search.best_params_['window']\n",
    "best_mse = -grid_search.best_score_\n",
    "\n",
    "print(f\"A melhor média móvel é de {best_window} dias, com MSE de {best_mse:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a melhor média móvel com o período encontrado pelo GridSearch\n",
    "best_moving_average = data['Close'].rolling(window=best_window).mean()\n",
    "\n",
    "# Criando colunas para sinal de compra (1), sinal de venda (-1) e sinal neutro (0)\n",
    "data['Buy_Signal'] = np.where(data['Close'] > best_moving_average, 1, 0)\n",
    "data['Sell_Signal'] = np.where(data['Close'] < best_moving_average, -1, 0)\n",
    "\n",
    "# Calculando o lucro e a perda (PnL) da estratégia\n",
    "data['PnL'] = data['Close'].pct_change() * data['Buy_Signal'].shift(-1)\n",
    "\n",
    "# Calculando o retorno cumulativo\n",
    "data['Cumulative_Return'] = (1 + data['PnL']).cumprod()\n",
    "\n",
    "# Visualizando os resultados\n",
    "print(data[['Close', 'Buy_Signal', 'Sell_Signal', 'PnL', 'Cumulative_Return']].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do retorno anualizado\n",
    "days_per_year = 252  # Supondo que há 252 dias úteis em um ano\n",
    "total_trading_days = data['PnL'].count()\n",
    "annualized_return = ((data['Cumulative_Return'].iloc[-1]) ** (days_per_year / total_trading_days)) - 1\n",
    "\n",
    "# Cálculo do risco livre (pode ser ajustado de acordo com a taxa livre de risco atual)\n",
    "risk_free_rate = 0.03  # Exemplo: 3% ao ano\n",
    "\n",
    "# Cálculo do índice de Sharpe\n",
    "daily_returns = data['PnL']\n",
    "daily_risk_free_rate = (1 + risk_free_rate) ** (1 / days_per_year) - 1\n",
    "daily_volatility = daily_returns.std()\n",
    "sharpe_ratio = (daily_returns.mean() - daily_risk_free_rate) / daily_volatility\n",
    "\n",
    "# Cálculo do drawdown máximo\n",
    "cumulative_returns = data['Cumulative_Return']\n",
    "previous_peaks = cumulative_returns.cummax()\n",
    "drawdowns = cumulative_returns / previous_peaks - 1\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "# Visualizando as métricas\n",
    "print(f\"Retorno anualizado: {annualized_return:.2%}\")\n",
    "print(f\"Índice de Sharpe: {sharpe_ratio:.2f}\")\n",
    "print(f\"Drawdown máximo: {max_drawdown:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Preparação dos dados para o modelo de machine learning\n",
    "X = data[['Close']].shift(1).dropna()  # Usamos o preço de fechamento do dia anterior como feature\n",
    "y = data['Buy_Signal'].shift(-1).dropna()  # O sinal de compra do próximo dia é o rótulo\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Criação e treinamento do modelo de Regressão Logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_output = classification_report(y_test, y_pred)\n",
    "\n",
    "# Visualizando os resultados\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Criação e treinamento do modelo SVM\n",
    "model_svm = SVC(kernel='linear', C=1.0)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_report_output_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Visualizando os resultados do modelo SVM\n",
    "print(f\"Acurácia do modelo SVM: {accuracy_svm:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo SVM:\\n\", classification_report_output_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Criação e treinamento do modelo de Rede Neural\n",
    "model_nn = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(1,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_nn.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_nn = model_nn.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo de Rede Neural\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "classification_report_output_nn = classification_report(y_test, y_pred_nn)\n",
    "\n",
    "# Visualizando os resultados do modelo de Rede Neural\n",
    "print(f\"Acurácia do modelo de Rede Neural: {accuracy_nn:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo de Rede Neural:\\n\", classification_report_output_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Criação e treinamento do modelo ARIMA\n",
    "model_arima = ARIMA(X_train, order=(5, 1, 0))  # Ordem (p, d, q) ajustável conforme necessário\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_arima = model_arima_fit.forecast(steps=len(X_test))[0]\n",
    "\n",
    "# Convertendo as previsões para sinais de compra e venda\n",
    "y_pred_arima_signals = np.where(y_pred_arima > X_test['Close'], 1, -1)\n",
    "\n",
    "# Avaliando o desempenho do modelo ARIMA\n",
    "accuracy_arima = accuracy_score(y_test, y_pred_arima_signals)\n",
    "classification_report_output_arima = classification_report(y_test, y_pred_arima_signals)\n",
    "\n",
    "# Visualizando os resultados do modelo ARIMA\n",
    "print(f\"Acurácia do modelo ARIMA: {accuracy_arima:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo ARIMA:\\n\", classification_report_output_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Preparação dos dados para o modelo LSTM\n",
    "X_train_lstm = X_train.values.reshape(-1, 1, 1)\n",
    "X_test_lstm = X_test.values.reshape(-1, 1, 1)\n",
    "\n",
    "# Criação e treinamento do modelo LSTM\n",
    "model_lstm = Sequential([\n",
    "    LSTM(64, input_shape=(1, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train_lstm, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_lstm = model_lstm.predict(X_test_lstm)\n",
    "\n",
    "# Avaliando o desempenho do modelo LSTM\n",
    "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "classification_report_output_lstm = classification_report(y_test, y_pred_lstm)\n",
    "\n",
    "# Visualizando os resultados do modelo LSTM\n",
    "print(f\"Acurácia do modelo LSTM: {accuracy_lstm:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo LSTM:\\n\", classification_report_output_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.action_space = gym.spaces.Discrete(3)  # 0: não fazer nada, 1: comprar, 2: vender\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.profit = 0\n",
    "        self.holdings = 0\n",
    "        self.initial_balance = 1000  # Defina o saldo inicial desejado\n",
    "        self.balance = self.initial_balance\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return np.array([self.data['Close'].iloc[self.current_step] / self.data['Close'].max()])\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        if action == 1:  # Comprar\n",
    "            if self.holdings == 0:\n",
    "                self.holdings = self.balance / self.data['Close'].iloc[self.current_step]\n",
    "                self.balance = 0\n",
    "\n",
    "        elif action == 2:  # Vender\n",
    "            if self.holdings > 0:\n",
    "                self.balance = self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "                self.holdings = 0\n",
    "\n",
    "        # Calcular a recompensa\n",
    "        current_balance = self.balance + self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "        self.profit = (current_balance - self.initial_balance) / self.initial_balance\n",
    "\n",
    "        # Verificar se o episódio terminou (pode adicionar outras condições de término)\n",
    "        done = self.current_step == len(self.data) - 1\n",
    "\n",
    "        # Definir a recompensa\n",
    "        if done:\n",
    "            reward = self.profit\n",
    "        else:\n",
    "            reward = self.profit - 0.001  # Penalidade diária para incentivar ações mais curtas\n",
    "\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Criação do ambiente de trading\n",
    "env = TradingEnv(data)\n",
    "\n",
    "# Implementação do algoritmo Q-Learning (neste exemplo, não estamos realizando o treinamento, mas você pode implementá-lo)\n",
    "def q_learning(env, num_episodes=100):\n",
    "    q_table = np.zeros((len(env.observation_space.high), env.action_space.n))\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = np.argmax(q_table[state])\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Atualizar a tabela Q\n",
    "            q_table[state, action] = (1 - 0.1) * q_table[state, action] + 0.1 * (reward + 0.9 * np.max(q_table[new_state]))\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "q_learning(env)\n",
    "\n",
    "# Teste da estratégia treinada\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state])\n",
    "    state, _, done, _ = env.step(action)\n",
    "\n",
    "final_profit = env.profit\n",
    "print(f\"Lucro final da estratégia: {final_profit:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data[['Close']])\n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - 1):\n",
    "    X.append(data_scaled[i])\n",
    "    y.append(data_scaled[i + 1][0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape dos dados para o formato [amostras, tempo, características]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Criação e treinamento do modelo LSTM\n",
    "model_lstm = Sequential([\n",
    "    LSTM(64, input_shape=(1, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Transformando as previsões para a escala original\n",
    "y_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Convertendo as previsões para sinais de compra e venda\n",
    "y_pred_signals = np.where(y_pred_lstm > y_test, 1, -1)\n",
    "\n",
    "# Avaliando o desempenho do modelo LSTM\n",
    "accuracy_lstm = accuracy_score(y_test, y_pred_signals)\n",
    "classification_report_output_lstm = classification_report(y_test, y_pred_signals)\n",
    "\n",
    "# Visualizando os resultados do modelo LSTM\n",
    "print(f\"Acurácia do modelo LSTM: {accuracy_lstm:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo LSTM:\\n\", classification_report_output_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data[['Close']])\n",
    "X, y = [], []\n",
    "look_back = 10  # Defina o tamanho da janela temporal\n",
    "for i in range(len(data_scaled) - look_back):\n",
    "    X.append(data_scaled[i:i + look_back])\n",
    "    y.append(data_scaled[i + look_back])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo CNN\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(look_back, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_cnn.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_cnn = model_cnn.predict(X_test)\n",
    "\n",
    "# Transformando as previsões para a escala original\n",
    "y_pred_cnn = scaler.inverse_transform(y_pred_cnn)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Convertendo as previsões para sinais de compra e venda\n",
    "y_pred_signals = np.where(y_pred_cnn > y_test, 1, -1)\n",
    "\n",
    "# Avaliando o desempenho do modelo CNN\n",
    "accuracy_cnn = accuracy_score(y_test, y_pred_signals)\n",
    "classification_report_output_cnn = classification_report(y_test, y_pred_signals)\n",
    "\n",
    "# Visualizando os resultados do modelo CNN\n",
    "print(f\"Acurácia do modelo CNN: {accuracy_cnn:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo CNN:\\n\", classification_report_output_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo XGBoost\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "classification_report_output_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "# Visualizando os resultados do modelo XGBoost\n",
    "print(f\"Acurácia do modelo XGBoost: {accuracy_xgb:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo XGBoost:\\n\", classification_report_output_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Criação e treinamento do modelo Random Forest\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_report_output_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Visualizando os resultados do modelo Random Forest\n",
    "print(f\"Acurácia do modelo Random Forest: {accuracy_rf:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo Random Forest:\\n\", classification_report_output_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Preparação dos dados\n",
    "data['Target'] = np.where(data['Close'].shift(-1) > data['Close'], 1, -1)\n",
    "\n",
    "X = data[['Close']]\n",
    "y = data['Target']\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape dos dados para o formato adequado\n",
    "look_back = 10\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], look_back, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], look_back, 1))\n",
    "\n",
    "# Criação e treinamento do modelo híbrido LSTM + CNN\n",
    "model_hybrid = Sequential([\n",
    "    LSTM(64, input_shape=(look_back, 1), return_sequences=True),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_hybrid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_hybrid.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Realizando as previsões para o conjunto de teste\n",
    "y_pred_hybrid = model_hybrid.predict_classes(X_test)\n",
    "\n",
    "# Avaliando o desempenho do modelo híbrido LSTM + CNN\n",
    "accuracy_hybrid = accuracy_score(y_test, y_pred_hybrid)\n",
    "classification_report_output_hybrid = classification_report(y_test, y_pred_hybrid)\n",
    "\n",
    "# Visualizando os resultados do modelo híbrido LSTM + CNN\n",
    "print(f\"Acurácia do modelo híbrido LSTM + CNN: {accuracy_hybrid:.2f}\")\n",
    "print(\"Relatório de Classificação do modelo híbrido LSTM + CNN:\\n\", classification_report_output_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.action_space = spaces.Discrete(3)  # 0: não fazer nada, 1: comprar, 2: vender\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.profit = 0\n",
    "        self.holdings = 0\n",
    "        self.initial_balance = 1000  # Defina o saldo inicial desejado\n",
    "        self.balance = self.initial_balance\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return np.array([self.data['Close'].iloc[self.current_step] / self.data['Close'].max()])\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        if action == 1:  # Comprar\n",
    "            if self.holdings == 0:\n",
    "                self.holdings = self.balance / self.data['Close'].iloc[self.current_step]\n",
    "                self.balance = 0\n",
    "\n",
    "        elif action == 2:  # Vender\n",
    "            if self.holdings > 0:\n",
    "                self.balance = self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "                self.holdings = 0\n",
    "\n",
    "        # Calcular a recompensa\n",
    "        current_balance = self.balance + self.holdings * self.data['Close'].iloc[self.current_step]\n",
    "        self.profit = (current_balance - self.initial_balance) / self.initial_balance\n",
    "\n",
    "        # Verificar se o episódio terminou (pode adicionar outras condições de término)\n",
    "        done = self.current_step == len(self.data) - 1\n",
    "\n",
    "        # Definir a recompensa\n",
    "        if done:\n",
    "            reward = self.profit\n",
    "        else:\n",
    "            reward = self.profit - 0.001  # Penalidade diária para incentivar ações mais curtas\n",
    "\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "# Carregar os dados históricos do arquivo CSV\n",
    "data = pd.read_csv('data_/AAPL.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Criação do ambiente de trading\n",
    "env = TradingEnv(data)\n",
    "\n",
    "# Implementação do algoritmo Deep Q-Network (DQN)\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Fator de desconto\n",
    "        self.epsilon = 1.0  # Probabilidade de exploração inicial\n",
    "        self.epsilon_decay = 0.995  # Taxa de decaimento da probabilidade de exploração\n",
    "        self.epsilon_min = 0.01  # Probabilidade mínima de exploração\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Configuração do agente DQN\n",
    "state_size = 1\n",
    "action_size = 3\n",
    "batch_size = 32\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# Treinamento do agente DQN\n",
    "for e in range(100):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"Época: {}/{}, Lucro: {:.2f}\"\n",
    "                  .format(e, 100, env.profit))\n",
    "            break\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "# Teste da estratégia aprendida\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, state_size])\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "final_profit = env.profit\n",
    "print(f\"Lucro final da estratégia: {final_profit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
